#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
New LLM Providers Demo - æ–° LLM æä¾›å•†æ¼”ç¤º

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°å¢çš„ LLM æä¾›å•†:
- AI21 Labs (Jurassic ç³»åˆ—)
- Cerebras (Llama, Qwen ç³»åˆ—)
- Cloudflare Workers AI (è¾¹ç¼˜ AI)

Usage:
    python examples/new_providers_demo.py
"""

import asyncio
import os
from typing import List, Dict

# è®¾ç½®ç¯å¢ƒå˜é‡ (å®é™…ä½¿ç”¨æ—¶è¯·ä½¿ç”¨çœŸå®çš„ API keys)
os.environ.setdefault("AI21_API_KEY", "your-ai21-api-key")
os.environ.setdefault("CEREBRAS_API_KEY", "your-cerebras-api-key")
os.environ.setdefault("CLOUDFLARE_API_TOKEN", "your-cloudflare-api-token")
os.environ.setdefault("CLOUDFLARE_ACCOUNT_ID", "your-account-id")


async def demo_ai21_provider():
    """æ¼”ç¤º AI21 Provider"""
    print("\n" + "=" * 60)
    print("ğŸ¤– AI21 Labs Provider Demo (Jurassic Series)")
    print("=" * 60)

    from agent_os_kernel.llm.ai21_provider import AI21Provider
    from agent_os_kernel.llm.provider import LLMConfig, ProviderType

    # åˆ›å»ºé…ç½®
    config = LLMConfig(
        provider=ProviderType.AI21,
        model="j2-ultra",  # æˆ– j2-core, j2-7b-instruct
        api_key=os.getenv("AI21_API_KEY"),
        max_tokens=1000,
        temperature=0.7
    )

    # åˆ›å»º Provider
    provider = AI21Provider(config)

    print(f"\nProvider: {provider.provider_name}")
    print(f"Model: {provider.config.model}")
    print(f"Supported Models: {provider.supported_models}")

    try:
        # åˆå§‹åŒ–
        await provider.initialize()
        print("âœ… Provider initialized successfully")

        # æ¨¡æ‹Ÿæ¶ˆæ¯
        from agent_os_kernel.llm.provider import Message
        messages = [
            Message(role="system", content="You are a helpful AI assistant."),
            Message(role="user", content="What are the key features of Jurassic-2?")
        ]

        print("\nğŸ“¤ Sending request to AI21...")
        # æ³¨æ„: å®é™…è°ƒç”¨éœ€è¦æœ‰æ•ˆçš„ API key
        # response = await provider.complete(messages)
        # print(f"ğŸ“¥ Response: {response.content}")

        print("âœ… AI21 Provider demo completed")

    except Exception as e:
        print(f"âš ï¸  AI21 Demo (expected without API key): {e}")
    finally:
        await provider.shutdown()


async def demo_cerebras_provider():
    """æ¼”ç¤º Cerebras Provider"""
    print("\n" + "=" * 60)
    print("âš¡ Cerebras Provider Demo (High-Speed Inference)")
    print("=" * 60)

    from agent_os_kernel.llm.cerebras_provider import CerebrasProvider
    from agent_os_kernel.llm.provider import LLMConfig, ProviderType

    # åˆ›å»ºé…ç½®
    config = LLMConfig(
        provider=ProviderType.CEREBRAS,
        model="llama-3.1-8b",  # æˆ– llama-3.1-70b, qwen-2.5-7b-instruct
        api_key=os.getenv("CEREBRAS_API_KEY"),
        max_tokens=1000,
        temperature=0.7
    )

    # åˆ›å»º Provider
    provider = CerebrasProvider(config)

    print(f"\nProvider: {provider.provider_name}")
    print(f"Model: {provider.config.model}")
    print(f"Supported Models:")
    for model in provider.supported_models:
        print(f"  - {model}")

    try:
        # åˆå§‹åŒ–
        await provider.initialize()
        print("âœ… Provider initialized successfully")

        # æ¨¡æ‹Ÿæ¶ˆæ¯
        from agent_os_kernel.llm.provider import Message
        messages = [
            Message(role="user", content="Explain why Cerebras is fast.")
        ]

        print("\nğŸ“¤ Sending request to Cerebras...")
        # æ³¨æ„: å®é™…è°ƒç”¨éœ€è¦æœ‰æ•ˆçš„ API key
        # response = await provider.complete(messages)
        # print(f"ğŸ“¥ Response: {response.content}")

        # æµ‹è¯• token è®¡æ•°
        test_text = "Cerebras provides high-speed AI inference through its Wafer-Scale Engine."
        tokens = await provider.count_tokens(test_text)
        print(f"\nğŸ“Š Token estimation for test text: {tokens}")

        print("âœ… Cerebras Provider demo completed")

    except Exception as e:
        print(f"âš ï¸  Cerebras Demo (expected without API key): {e}")
    finally:
        await provider.shutdown()


async def demo_cloudflare_provider():
    """æ¼”ç¤º Cloudflare Provider"""
    print("\n" + "=" * 60)
    print("ğŸŒ¥ï¸  Cloudflare Workers AI Demo (Edge AI)")
    print("=" * 60)

    from agent_os_kernel.llm.cloudflare_provider import CloudflareProvider
    from agent_os_kernel.llm.provider import LLMConfig, ProviderType

    # åˆ›å»ºé…ç½®
    config = LLMConfig(
        provider=ProviderType.CLOUDFLARE,
        model="@cf/meta/llama-3-8b-instruct",  # æˆ– @cf/meta/llama-3-70b-instruct
        api_key=os.getenv("CLOUDFLARE_API_TOKEN"),
        max_tokens=1000,
        temperature=0.7
    )

    # åˆ›å»º Provider
    provider = CloudflareProvider(config)

    print(f"\nProvider: {provider.provider_name}")
    print(f"Model: {provider.config.model}")

    print("\nğŸ“‹ Available Models:")
    print("\n  Chat Models:")
    chat_models = await provider.list_models_by_type("chat")
    for model in chat_models[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"    - {model['id']} ({model['name']})")

    print("\n  Embedding Models:")
    embedding_models = await provider.list_models_by_type("embedding")
    for model in embedding_models:
        print(f"    - {model['id']} ({model['name']})")

    try:
        # åˆå§‹åŒ–
        await provider.initialize()
        print("\nâœ… Provider initialized successfully")

        # æ¨¡æ‹Ÿæ¶ˆæ¯
        from agent_os_kernel.llm.provider import Message
        messages = [
            Message(role="system", content="You are a helpful AI assistant."),
            Message(role="user", content="What are the benefits of edge AI?")
        ]

        print("\nğŸ“¤ Sending request to Cloudflare...")
        # æ³¨æ„: å®é™…è°ƒç”¨éœ€è¦æœ‰æ•ˆçš„ API key
        # response = await provider.complete(messages)
        # print(f"ğŸ“¥ Response: {response.content}")

        print("âœ… Cloudflare Provider demo completed")

    except Exception as e:
        print(f"âš ï¸  Cloudflare Demo (expected without API key): {e}")
    finally:
        await provider.shutdown()


async def demo_provider_comparison():
    """æä¾›å•†å¯¹æ¯”æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ“Š Provider Comparison")
    print("=" * 60)

    from agent_os_kernel.llm.factory import get_factory, ProviderType

    factory = get_factory()
    providers = factory.list_providers()

    print("\nğŸ¤– All Available Providers:")
    print("-" * 60)

    for info in providers:
        print(f"\nğŸ“Œ {info.name}")
        print(f"   Type: {info.type.value}")
        print(f"   Description: {info.description}")
        print(f"   API Key Required: {'Yes' if info.requires_api_key else 'No'}")
        print(f"   Local: {'Yes' if info.local else 'No'}")
        print(f"   Default Model: {info.default_model}")


async def demo_provider_factory():
    """ä½¿ç”¨ Factory åˆ›å»º Provider"""
    print("\n" + "=" * 60)
    print("ğŸ­ Provider Factory Demo")
    print("=" * 60)

    from agent_os_kernel.llm.factory import get_factory
    from agent_os_kernel.llm.provider import ProviderType

    factory = get_factory()

    # è·å–ç‰¹å®š Provider ä¿¡æ¯
    ai21_info = factory.get_provider_info("ai21")
    cerebras_info = factory.get_provider_info("cerebras")
    cloudflare_info = factory.get_provider_info("cloudflare")

    print("\nğŸ“‹ New Provider Details:")
    print(f"\n  AI21 Labs:")
    print(f"    - Type: {ai21_info.type.value}")
    print(f"    - Name: {ai21_info.name}")
    print(f"    - Requires API Key: {ai21_info.requires_api_key}")
    print(f"    - Default Model: {ai21_info.default_model}")

    print(f"\n  Cerebras:")
    print(f"    - Type: {cerebras_info.type.value}")
    print(f"    - Name: {cerebras_info.name}")
    print(f"    - Requires API Key: {cerebras_info.requires_api_key}")
    print(f"    - Default Model: {cerebras_info.default_model}")

    print(f"\n  Cloudflare Workers AI:")
    print(f"    - Type: {cloudflare_info.type.value}")
    print(f"    - Name: {cloudflare_info.name}")
    print(f"    - Requires API Key: {cloudflare_info.requires_api_key}")
    print(f"    - Default Model: {cloudflare_info.default_model}")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€" * 30)
    print("ğŸš€ New LLM Providers Demo ğŸš€")
    print("ğŸš€" * 30)

    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    await demo_ai21_provider()
    await demo_cerebras_provider()
    await demo_cloudflare_provider()
    await demo_provider_comparison()
    await demo_provider_factory()

    print("\n" + "=" * 60)
    print("âœ… All Demos Completed!")
    print("=" * 60)

    print("\nğŸ“š Usage Instructions:")
    print("-" * 60)
    print("""
1. AI21 Labs:
   - Sign up at https://www.ai21.com/
   - Get API key from dashboard
   - Set environment variable: AI21_API_KEY

2. Cerebras:
   - Sign up at https://cloud.cerebras.ai/
   - Get API key from dashboard
   - Set environment variable: CEREBRAS_API_KEY

3. Cloudflare Workers AI:
   - Sign up at https://cloudflare.com/
   - Enable Workers AI in dashboard
   - Get API token with AI permissions
   - Set environment variables:
     - CLOUDFLARE_API_TOKEN
     - CLOUDFLARE_ACCOUNT_ID
    """)


if __name__ == "__main__":
    asyncio.run(main())
